---
layout: post
title: "Waste Assist Classifiction"
subtitle: ""
background: '/img/posts/waste assist.jpg'
---

<h2<p><a href="https://github.com/Oluwachidi/waste-assist">github link</a>.</p></h2>

<h2 class="section-heading">Introduction</h2>
<p>Material mismatches and incorrect input cause expensive delays at sorting and processing  facilities</p>
<p>This project is to help people classify their waste accurately to improve residential waste sorting and also reduce material contamination thereby optimizing the process in recycling facilities for waste sorting.</p>

<p>This is achieved by designing an app for waste classification and detection using convolutional neural network(CNN) and transfer learning as well as creating an object detection model for sorting at the recyling facilities.</p>



<h2 class="section-heading">Dataset</h2>
<p>Dataset derived from TrashNet by Gary Thung and Mindy Yang with seven categories <a href="https://github.com/sarahmfrost/compostnet ">https://github.com/sarahmfrost/compostnet </a> and merged with recylable materials by Minho Heo <a href="https://www.kaggle.com/minhoheo/recyable-materials">https://www.kaggle.com/minhoheo/recyable-materials</a></p>
<p>additional images was obtained form friends, collegues and google image</p>

![waste categories](/img/posts/waste categories.jpg)  
<p>Around 3000 images in total , divided into a 80%/20% Train/Validation set.</p>
![urgumented image](/img/posts/Urgumented Images.jpg)



<h2 class="section-heading">Models</h2>
<p>An initial base model of Convolutional Neural Network with arround 11 million trianable parameters gave an accuracy of 62% which is higher than the baseline accuracy of 14% (1/7)</p>
<p>![base model](../img/posts/base model.jpg)</p>
<p>The model is further optimized through a Transfer Learning model known as ResNet152V2.</P>
<p>![ResNet152V2](../img/posts/ResNet152V2.jpg)</p>
<p>It is a Deep Residual Network with 152 layers of around 58 million pre-trained parameters and about 14000 trainable parameters.</p>
<img class="img-model" ![ResNet_Model](../img/posts/ResNet_Model.jpg) alt="ResNet_Model">
<p>A test accuracy of 84% was achived without any Hyper-parameter tunning</p>
<p>Finally, a single neural network called YOLOv5 is applied to the full image divided into regions for a real time object detection</p>
<p>See link for a real time demo: <a href="https://www.youtube.com/watch?v=8IQFmcnqFHA">Live-object-detection-video</a></p>



<h2 class="section-heading">App and Model Deployment</h2>
<p>The packaged(packgenlite tool) python code is uploaded on GCP and wth the power of cloud computing, the model is trained on the google cloud virtual machine (AI Platform)</p>
<p>The app is finally deployed through the followig processes</p>

<ul>
  <li>Build a predictive API with FastAPI</li>
  <li>Build a user interface with Streamlit</li>
  <li>Mount the API in a Docker container</li>
  <li>Plug the API to a user interface to build a predictive product</li>
  <li>Deploy the API on Google Cloud Run to make prediction in production</li>
  <li>Deploy a user interface on Heroku for your predictive product</li>
</ul>

<p>app_link <a href="https://wasteassist.herokuapp.com/">waste-assist-app</a>.</p>
![deployment apps](/img/posts/deployment apps.jpg)

<h2 class="section-heading">Performance</h2>
<p>The software can now... </p>
 <ul>
  <li>sort recyclable waste at high levels of accuracy (85%-90%)</li>
  <li>recognize the material of objects presented in a video feed</li>
</ul> 

<p>In the future, the plan is to... </p>
 <ul>
  <li>engage with all facilities in Montreal who sort, in the waste processing industry and beyond, </li>
  <li>explore automating physical sorting processes, and </li>
  <li>inspire personal involvement in sorting and technology among  the general public </li>
</ul>

<img class="img-fluid" src="https://source.unsplash.com/Mn9Fa_wQH-M/800x450" alt="Demo Image">
